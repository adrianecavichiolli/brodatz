{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from brodatz.data_utils import process_file, process_file_some_classes, read_some_classes, save_model, read_train_test_sets, save_history\n",
    "from brodatz.utils import probas_to_classes, accuracy, curr_date, try_args_generator, try_args, save_predict_classes\n",
    "from brodatz.visualization_utils import plot_image, plot, plot_history, plot_confusion_matrix\n",
    "\n",
    "from brodatz.models.keras_neural_net import KerasNeuralNetwork\n",
    "\n",
    "from brodatz.brodatz_generator import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras import regularizers, optimizers, utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove prefixes\n",
    "import os\n",
    "path = '/mnt/82db778e-0496-450c-9b25-d1e50a90e476/data/data4stas/01_data_cls'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'Alexander_cls_train.csv'\n",
    "test_filenames = ['Alexander_cls_test.csv',\n",
    "                  'Alexander_cls_test1.csv',\n",
    "                  'Alexander_cls_test2.csv',\n",
    "                  'Alexander_cls_test3.csv',\n",
    "                  'Alexander_cls_test4.csv']\n",
    "classes_range = np.arange(0, 111)\n",
    "X_train, y_train, num_classes, X_val, y_val, test_list = read_train_test_sets(train_filename, test_filenames, classes_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '/home/stanislau/repository/machine-learning/brodatz/results/'\n",
    "directory_names = ['24.11.2017 22:54:11', '25.11.2017 1:38:8', '25.11.2017 21:57:27', '25.11.2017 7:9:14']\n",
    "directory_name = root_directory + directory_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 53.29%\n",
      "Loaded model from disk\n",
      "acc: 37.34%\n",
      "Loaded model from disk\n",
      "acc: 37.48%\n",
      "Loaded model from disk\n",
      "acc: 57.43%\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(4):\n",
    "    directory_name = root_directory + directory_names[i]\n",
    "    \n",
    "    \n",
    "    json_file = open(directory_name + '/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(directory_name + \"/model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "    with open(directory_name + \"/optimizer.json\", \"r\") as json_file:\n",
    "        optimizer_json = json_file.read()  # read optimizer from file\n",
    "\n",
    "    # if optimizer_json:\n",
    "    #     optimizer = optimizers.deserialize(optimizer_json)\n",
    "    #     print('Loaded optimizer from disk')\n",
    "    # else:\n",
    "    optimizer = optimizers.SGD(lr=0.002, decay=0, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "    # evaluate loaded model on test data\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    score = loaded_model.evaluate(test_list[0][0], test_list[0][1], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "    \n",
    "    models.append(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.models.Sequential at 0x7f2530686780>,\n",
       " <keras.models.Sequential at 0x7f24c59ba588>,\n",
       " <keras.models.Sequential at 0x7f24c5807cc0>,\n",
       " <keras.models.Sequential at 0x7f24c56e69e8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [models[i].predict(test_list[0][0]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.asarray(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max = np.max(y_preds, axis=0)\n",
    "y_pred_cls = np.argmax(model_max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_avr = np.mean(y_preds, axis=0)\n",
    "y_pred_cls = np.argmax(model_avr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_avr = 0.35 * y_preds[0] + 0.15 * y_preds[1] + 0.15 * y_preds[2] + 0.35 * y_preds[3]\n",
    "y_pred_cls = np.argmax(model_avr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cls = np.argmax(test_list[0][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75045045045045045"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred_cls == y_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predict_classes(y_pred_cls + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
