{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove prefixes\n",
    "import os\n",
    "path = '/media/stanislau/82db778e-0496-450c-9b25-d1e50a90e476/data/data4stas/01_data_cls'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        x.append(cv2.imread(row['FilePath'], cv2.IMREAD_GRAYSCALE))\n",
    "        y.append(float(row['ClassId']))\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "\n",
    "    x = x.reshape(x.shape + (-1,))\n",
    "    y = y - 1\n",
    "    y = keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    return x, y, num_classes\n",
    "\n",
    "def process_file2(path, classes):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        x.append(cv2.imread(row['FilePath'], cv2.IMREAD_GRAYSCALE))\n",
    "        y.append(float(row['ClassId']))\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    x = x.reshape(x.shape + (-1,))\n",
    "    y = y - 1\n",
    "    \n",
    "    indexes = np.argwhere(y < classes)\n",
    "    \n",
    "    y = y[indexes]\n",
    "    x = x[indexes.ravel()]\n",
    "    \n",
    "    y = keras.utils.to_categorical(y, num_classes=classes)\n",
    "\n",
    "    return x, y, classes\n",
    "\n",
    "\n",
    "def process_line(line):\n",
    "    pass\n",
    "\n",
    "def generate_arrays_from_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            # create numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x1, x2, y = process_line(line)\n",
    "            yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y, num_classes = process_file('Alexander_cls_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, num_classes = process_file2('Alexander_cls_train.csv', classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 200, 200, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=7,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "#     shear_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     zoom_range=0.2,\n",
    "    fill_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (5, 5),\n",
    "    (7, 7),\n",
    "    (10, 10),\n",
    "    (12, 12)\n",
    "]\n",
    "\n",
    "filter_size = filters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 200x200 grayscale images -> (200, 200, 1) tensors.\n",
    "# this applies 8 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(64, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu', input_shape=(200, 200, 1)))\n",
    "model.add(Conv2D(64, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "# model.add(Conv2D(16, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(32, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(128, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "# model.add(Conv2D(32, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(256, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(256, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(128, (2, 2), activation='relu'))\n",
    "# model.add(Conv2D(64, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(512, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(512, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(512, (2, 2), activation='relu'))\n",
    "# model.add(Conv2D(128, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(512, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(512, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(Conv2D(512, filter_size, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# # # model.add(Conv2D(512, (2, 2), activation='relu'))\n",
    "# # # model.add(Conv2D(128, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(128, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(512, (2, 2), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(4096, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, kernel_regularizer=regularizers.l2(0.01), activation='softmax'), )\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x, y, batch_size=8, epochs=10, validation_data=(x_train, y_train))\n",
    "model.fit(x, y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s - loss: nan - acc: 0.1000     \n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s - loss: nan - acc: 0.1000     \n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: nan - acc: 0.1000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-0b03bfaeb0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit_generator(datagen.flow(x, y, batch_size=batch_size),\n\u001b[0;32m----> 3\u001b[0;31m                     steps_per_epoch=len(x) / batch_size * 10, epochs=10)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "model.fit_generator(datagen.flow(x, y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x) / batch_size * 10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "35/34 [==============================] - 20s - loss: 25.5768 - acc: 0.0107    \n",
      "Epoch 2/700\n",
      "35/34 [==============================] - 19s - loss: 23.0350 - acc: 0.0098    \n",
      "Epoch 3/700\n",
      "35/34 [==============================] - 20s - loss: 21.6410 - acc: 0.0080    \n",
      "Epoch 4/700\n",
      "35/34 [==============================] - 21s - loss: 19.8045 - acc: 0.0134    \n",
      "Epoch 5/700\n",
      "35/34 [==============================] - 20s - loss: 18.7373 - acc: 0.0134    \n",
      "Epoch 6/700\n",
      "35/34 [==============================] - 21s - loss: 17.3927 - acc: 0.0152    \n",
      "Epoch 7/700\n",
      "35/34 [==============================] - 20s - loss: 16.1347 - acc: 0.0214    \n",
      "Epoch 8/700\n",
      "35/34 [==============================] - 20s - loss: 15.2032 - acc: 0.0250    \n",
      "Epoch 9/700\n",
      "35/34 [==============================] - 20s - loss: 14.5017 - acc: 0.0304    \n",
      "Epoch 10/700\n",
      "35/34 [==============================] - 18s - loss: 13.9926 - acc: 0.0325    \n",
      "Epoch 11/700\n",
      "35/34 [==============================] - 16s - loss: 13.8043 - acc: 0.0320    \n",
      "Epoch 12/700\n",
      "35/34 [==============================] - 20s - loss: 13.0744 - acc: 0.0357    \n",
      "Epoch 13/700\n",
      "35/34 [==============================] - 20s - loss: 12.6212 - acc: 0.0295    \n",
      "Epoch 14/700\n",
      "35/34 [==============================] - 20s - loss: 12.0997 - acc: 0.0330    \n",
      "Epoch 15/700\n",
      "35/34 [==============================] - 20s - loss: 11.8690 - acc: 0.0437    \n",
      "Epoch 16/700\n",
      "35/34 [==============================] - 20s - loss: 11.6200 - acc: 0.0437    \n",
      "Epoch 17/700\n",
      "35/34 [==============================] - 20s - loss: 11.3941 - acc: 0.0545    \n",
      "Epoch 18/700\n",
      "35/34 [==============================] - 20s - loss: 11.0794 - acc: 0.0500    \n",
      "Epoch 19/700\n",
      "35/34 [==============================] - 20s - loss: 10.9985 - acc: 0.0607    \n",
      "Epoch 20/700\n",
      "35/34 [==============================] - 19s - loss: 10.6182 - acc: 0.0717    \n",
      "Epoch 21/700\n",
      "35/34 [==============================] - 15s - loss: 10.8261 - acc: 0.0345    \n",
      "Epoch 22/700\n",
      "35/34 [==============================] - 20s - loss: 10.5939 - acc: 0.0482    \n",
      "Epoch 23/700\n",
      "35/34 [==============================] - 20s - loss: 10.3021 - acc: 0.0830    \n",
      "Epoch 24/700\n",
      "35/34 [==============================] - 20s - loss: 10.3037 - acc: 0.0839    \n",
      "Epoch 25/700\n",
      "35/34 [==============================] - 20s - loss: 10.2547 - acc: 0.0955    \n",
      "Epoch 26/700\n",
      "35/34 [==============================] - 20s - loss: 10.0110 - acc: 0.0911    \n",
      "Epoch 27/700\n",
      "35/34 [==============================] - 20s - loss: 10.0000 - acc: 0.0973   \n",
      "Epoch 28/700\n",
      "35/34 [==============================] - 20s - loss: 9.5974 - acc: 0.0902    \n",
      "Epoch 29/700\n",
      "35/34 [==============================] - 20s - loss: 10.1197 - acc: 0.0830    \n",
      "Epoch 30/700\n",
      "35/34 [==============================] - 19s - loss: 10.4564 - acc: 0.0828    \n",
      "Epoch 31/700\n",
      "35/34 [==============================] - 16s - loss: 10.3061 - acc: 0.0498    \n",
      "Epoch 32/700\n",
      "35/34 [==============================] - 18s - loss: 10.3774 - acc: 0.0659    \n",
      "Epoch 33/700\n",
      "35/34 [==============================] - 20s - loss: 9.4283 - acc: 0.1080    \n",
      "Epoch 34/700\n",
      "35/34 [==============================] - 20s - loss: 10.0129 - acc: 0.1080    \n",
      "Epoch 35/700\n",
      "35/34 [==============================] - 20s - loss: 9.3584 - acc: 0.1259    \n",
      "Epoch 36/700\n",
      "35/34 [==============================] - 20s - loss: 9.7663 - acc: 0.1045    \n",
      "Epoch 37/700\n",
      "35/34 [==============================] - 20s - loss: 9.4166 - acc: 0.1339    \n",
      "Epoch 38/700\n",
      "35/34 [==============================] - 20s - loss: 9.6710 - acc: 0.1339    \n",
      "Epoch 39/700\n",
      "35/34 [==============================] - 20s - loss: 9.5428 - acc: 0.1330    \n",
      "Epoch 40/700\n",
      "35/34 [==============================] - 19s - loss: 9.3116 - acc: 0.1428    \n",
      "Epoch 41/700\n",
      "35/34 [==============================] - 17s - loss: 9.4584 - acc: 0.1403    \n",
      "Epoch 42/700\n",
      "35/34 [==============================] - 17s - loss: 9.6626 - acc: 0.1105    \n",
      "Epoch 43/700\n",
      "35/34 [==============================] - 20s - loss: 8.9881 - acc: 0.1750    \n",
      "Epoch 44/700\n",
      "35/34 [==============================] - 20s - loss: 9.3720 - acc: 0.1536    \n",
      "Epoch 45/700\n",
      "35/34 [==============================] - 20s - loss: 9.2321 - acc: 0.1946    \n",
      "Epoch 46/700\n",
      "35/34 [==============================] - 20s - loss: 9.8920 - acc: 0.1321    \n",
      "Epoch 47/700\n",
      "35/34 [==============================] - 20s - loss: 9.4003 - acc: 0.1634    \n",
      "Epoch 48/700\n",
      "35/34 [==============================] - 20s - loss: 9.8476 - acc: 0.1616    \n",
      "Epoch 49/700\n",
      "35/34 [==============================] - 20s - loss: 9.2884 - acc: 0.1750    \n",
      "Epoch 50/700\n",
      "35/34 [==============================] - 20s - loss: 9.3286 - acc: 0.1991    \n",
      "Epoch 51/700\n",
      "35/34 [==============================] - 18s - loss: 9.2051 - acc: 0.1729    \n",
      "Epoch 52/700\n",
      "35/34 [==============================] - 15s - loss: 9.6278 - acc: 0.1345    \n",
      "Epoch 53/700\n",
      "35/34 [==============================] - 20s - loss: 9.3788 - acc: 0.1839    \n",
      "Epoch 54/700\n",
      "35/34 [==============================] - 20s - loss: 9.2602 - acc: 0.1964    \n",
      "Epoch 55/700\n",
      "35/34 [==============================] - 20s - loss: 9.9248 - acc: 0.1866    \n",
      "Epoch 56/700\n",
      "35/34 [==============================] - 20s - loss: 9.0908 - acc: 0.2134    \n",
      "Epoch 57/700\n",
      "35/34 [==============================] - 20s - loss: 9.1885 - acc: 0.1866    \n",
      "Epoch 58/700\n",
      "35/34 [==============================] - 20s - loss: 9.4197 - acc: 0.1714    \n",
      "Epoch 59/700\n",
      "35/34 [==============================] - 20s - loss: 9.4360 - acc: 0.2116    \n",
      "Epoch 60/700\n",
      "35/34 [==============================] - 20s - loss: 9.5095 - acc: 0.2152    \n",
      "Epoch 61/700\n",
      "35/34 [==============================] - 18s - loss: 9.3261 - acc: 0.2152    \n",
      "Epoch 62/700\n",
      "35/34 [==============================] - 15s - loss: 9.5726 - acc: 0.1838    \n",
      "Epoch 63/700\n",
      "35/34 [==============================] - 20s - loss: 9.6150 - acc: 0.1723    \n",
      "Epoch 64/700\n",
      "35/34 [==============================] - 20s - loss: 9.7679 - acc: 0.1884    \n",
      "Epoch 65/700\n",
      "35/34 [==============================] - 20s - loss: 9.6258 - acc: 0.2232    \n",
      "Epoch 66/700\n",
      "35/34 [==============================] - 20s - loss: 9.2923 - acc: 0.2420    \n",
      "Epoch 67/700\n",
      "35/34 [==============================] - 20s - loss: 9.4744 - acc: 0.2268    \n",
      "Epoch 68/700\n",
      "35/34 [==============================] - 20s - loss: 9.2468 - acc: 0.2375    \n",
      "Epoch 69/700\n",
      "35/34 [==============================] - 20s - loss: 9.4839 - acc: 0.2214    \n",
      "Epoch 70/700\n",
      "35/34 [==============================] - 20s - loss: 9.3594 - acc: 0.2429    \n",
      "Epoch 71/700\n",
      "35/34 [==============================] - 19s - loss: 9.3266 - acc: 0.2513    \n",
      "Epoch 72/700\n",
      "35/34 [==============================] - 17s - loss: 9.3177 - acc: 0.2088    \n",
      "Epoch 73/700\n",
      "35/34 [==============================] - 18s - loss: 9.3338 - acc: 0.1771    \n",
      "Epoch 74/700\n",
      "35/34 [==============================] - 20s - loss: 9.0972 - acc: 0.2429    \n",
      "Epoch 75/700\n",
      "35/34 [==============================] - 20s - loss: 9.3583 - acc: 0.2723    \n",
      "Epoch 76/700\n",
      "35/34 [==============================] - 20s - loss: 9.7322 - acc: 0.2062    \n",
      "Epoch 77/700\n",
      "35/34 [==============================] - 20s - loss: 8.8270 - acc: 0.2732    \n",
      "Epoch 78/700\n",
      "35/34 [==============================] - 20s - loss: 9.4682 - acc: 0.2429    \n",
      "Epoch 79/700\n",
      "35/34 [==============================] - 20s - loss: 9.3008 - acc: 0.2527    \n",
      "Epoch 80/700\n",
      "35/34 [==============================] - 20s - loss: 9.3609 - acc: 0.2295    \n",
      "Epoch 81/700\n",
      "35/34 [==============================] - 20s - loss: 9.0125 - acc: 0.2812    \n",
      "Epoch 82/700\n",
      "35/34 [==============================] - 18s - loss: 9.1058 - acc: 0.2339    \n",
      "Epoch 83/700\n",
      "35/34 [==============================] - 15s - loss: 9.8748 - acc: 0.2051    \n",
      "Epoch 84/700\n",
      "35/34 [==============================] - 20s - loss: 9.1818 - acc: 0.2866    \n",
      "Epoch 85/700\n",
      "35/34 [==============================] - 20s - loss: 9.2306 - acc: 0.2768    \n",
      "Epoch 86/700\n",
      "35/34 [==============================] - 20s - loss: 9.0353 - acc: 0.2857    \n",
      "Epoch 87/700\n",
      "35/34 [==============================] - 20s - loss: 9.0857 - acc: 0.2688    \n",
      "Epoch 88/700\n",
      "35/34 [==============================] - 20s - loss: 8.9146 - acc: 0.2786    \n",
      "Epoch 89/700\n",
      "35/34 [==============================] - 20s - loss: 8.8919 - acc: 0.2982    \n",
      "Epoch 90/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/34 [==============================] - 20s - loss: 9.4127 - acc: 0.2679    \n",
      "Epoch 91/700\n",
      "35/34 [==============================] - 20s - loss: 9.1974 - acc: 0.2795    \n",
      "Epoch 92/700\n",
      "35/34 [==============================] - 18s - loss: 9.3202 - acc: 0.2555    \n",
      "Epoch 93/700\n",
      "35/34 [==============================] - 15s - loss: 9.5363 - acc: 0.2136    \n",
      "Epoch 94/700\n",
      "35/34 [==============================] - 20s - loss: 9.3087 - acc: 0.2696    \n",
      "Epoch 95/700\n",
      "35/34 [==============================] - 20s - loss: 9.3063 - acc: 0.2777    \n",
      "Epoch 96/700\n",
      "35/34 [==============================] - 20s - loss: 9.2484 - acc: 0.2884    \n",
      "Epoch 97/700\n",
      "35/34 [==============================] - 20s - loss: 9.0494 - acc: 0.2857    \n",
      "Epoch 98/700\n",
      "35/34 [==============================] - 20s - loss: 9.0541 - acc: 0.2893    \n",
      "Epoch 99/700\n",
      "35/34 [==============================] - 20s - loss: 9.0733 - acc: 0.2875    \n",
      "Epoch 100/700\n",
      "35/34 [==============================] - 20s - loss: 9.1548 - acc: 0.2991    \n",
      "Epoch 101/700\n",
      "35/34 [==============================] - 20s - loss: 8.9279 - acc: 0.2866    \n",
      "Epoch 102/700\n",
      "35/34 [==============================] - 19s - loss: 9.5072 - acc: 0.2690    \n",
      "Epoch 103/700\n",
      "35/34 [==============================] - 16s - loss: 9.2273 - acc: 0.2332    \n",
      "Epoch 104/700\n",
      "35/34 [==============================] - 18s - loss: 9.6348 - acc: 0.2019    \n",
      "Epoch 105/700\n",
      "35/34 [==============================] - 20s - loss: 9.1665 - acc: 0.2821    \n",
      "Epoch 106/700\n",
      "35/34 [==============================] - 20s - loss: 9.3162 - acc: 0.2821    \n",
      "Epoch 107/700\n",
      "35/34 [==============================] - 20s - loss: 9.5157 - acc: 0.2821    \n",
      "Epoch 108/700\n",
      "35/34 [==============================] - 20s - loss: 9.5556 - acc: 0.2902    \n",
      "Epoch 109/700\n",
      "35/34 [==============================] - 20s - loss: 9.2783 - acc: 0.3161    \n",
      "Epoch 110/700\n",
      "35/34 [==============================] - 20s - loss: 9.0921 - acc: 0.3205    \n",
      "Epoch 111/700\n",
      "35/34 [==============================] - 20s - loss: 9.0069 - acc: 0.3161    \n",
      "Epoch 112/700\n",
      "35/34 [==============================] - 19s - loss: 9.5528 - acc: 0.2989    \n",
      "Epoch 113/700\n",
      "35/34 [==============================] - 17s - loss: 9.3691 - acc: 0.2714    \n",
      "Epoch 114/700\n",
      "35/34 [==============================] - 16s - loss: 9.4341 - acc: 0.2216    \n",
      "Epoch 115/700\n",
      "35/34 [==============================] - 20s - loss: 9.3648 - acc: 0.2839    \n",
      "Epoch 116/700\n",
      "35/34 [==============================] - 20s - loss: 9.4299 - acc: 0.2768    \n",
      "Epoch 117/700\n",
      "35/34 [==============================] - 20s - loss: 8.8729 - acc: 0.3313    \n",
      "Epoch 118/700\n",
      "35/34 [==============================] - 20s - loss: 8.9167 - acc: 0.2893    \n",
      "Epoch 119/700\n",
      "35/34 [==============================] - 20s - loss: 9.2146 - acc: 0.2893    \n",
      "Epoch 120/700\n",
      "35/34 [==============================] - 20s - loss: 9.1297 - acc: 0.3250    \n",
      "Epoch 121/700\n",
      "35/34 [==============================] - 20s - loss: 9.1636 - acc: 0.3214    \n",
      "Epoch 122/700\n",
      "35/34 [==============================] - 20s - loss: 9.2974 - acc: 0.3107    \n",
      "Epoch 123/700\n",
      "35/34 [==============================] - 18s - loss: 9.6142 - acc: 0.2591    \n",
      "Epoch 124/700\n",
      "35/34 [==============================] - 15s - loss: 9.7715 - acc: 0.2165    \n",
      "Epoch 125/700\n",
      "35/34 [==============================] - 20s - loss: 9.2815 - acc: 0.2616    \n",
      "Epoch 126/700\n",
      "35/34 [==============================] - 20s - loss: 9.4148 - acc: 0.2616    \n",
      "Epoch 127/700\n",
      "35/34 [==============================] - 20s - loss: 8.8298 - acc: 0.3134    \n",
      "Epoch 128/700\n",
      "35/34 [==============================] - 20s - loss: 9.0079 - acc: 0.3036    \n",
      "Epoch 129/700\n",
      "35/34 [==============================] - 20s - loss: 9.3512 - acc: 0.3214    \n",
      "Epoch 130/700\n",
      "35/34 [==============================] - 20s - loss: 9.9716 - acc: 0.2777    \n",
      "Epoch 131/700\n",
      "35/34 [==============================] - 20s - loss: 9.3552 - acc: 0.3063    \n",
      "Epoch 132/700\n",
      "35/34 [==============================] - 20s - loss: 8.9991 - acc: 0.3116    \n",
      "Epoch 133/700\n",
      "35/34 [==============================] - 18s - loss: 9.1851 - acc: 0.3332    \n",
      "Epoch 134/700\n",
      "35/34 [==============================] - 15s - loss: 8.9301 - acc: 0.2953    \n",
      "Epoch 135/700\n",
      "35/34 [==============================] - 20s - loss: 9.2183 - acc: 0.2161    \n",
      "Epoch 136/700\n",
      "35/34 [==============================] - 20s - loss: 9.2515 - acc: 0.2955    \n",
      "Epoch 137/700\n",
      "35/34 [==============================] - 20s - loss: 9.1067 - acc: 0.3134    \n",
      "Epoch 138/700\n",
      "35/34 [==============================] - 20s - loss: 9.0542 - acc: 0.3384    \n",
      "Epoch 139/700\n",
      "35/34 [==============================] - 20s - loss: 9.2009 - acc: 0.3098    \n",
      "Epoch 140/700\n",
      "35/34 [==============================] - 20s - loss: 9.1190 - acc: 0.3313    \n",
      "Epoch 141/700\n",
      "35/34 [==============================] - 20s - loss: 9.4361 - acc: 0.2955    \n",
      "Epoch 142/700\n",
      "35/34 [==============================] - 20s - loss: 9.0944 - acc: 0.3500    \n",
      "Epoch 143/700\n",
      "35/34 [==============================] - 19s - loss: 8.8832 - acc: 0.3163    \n",
      "Epoch 144/700\n",
      "35/34 [==============================] - 16s - loss: 9.1330 - acc: 0.2976    \n",
      "Epoch 145/700\n",
      "35/34 [==============================] - 17s - loss: 10.0596 - acc: 0.2024    \n",
      "Epoch 146/700\n",
      "35/34 [==============================] - 20s - loss: 9.4795 - acc: 0.2937    \n",
      "Epoch 147/700\n",
      "35/34 [==============================] - 20s - loss: 9.1145 - acc: 0.3152    \n",
      "Epoch 148/700\n",
      "35/34 [==============================] - 20s - loss: 9.0155 - acc: 0.3357    \n",
      "Epoch 149/700\n",
      "35/34 [==============================] - 20s - loss: 9.3004 - acc: 0.3223    \n",
      "Epoch 150/700\n",
      "35/34 [==============================] - 20s - loss: 9.1246 - acc: 0.3286    \n",
      "Epoch 151/700\n",
      "35/34 [==============================] - 20s - loss: 9.0566 - acc: 0.3366    \n",
      "Epoch 152/700\n",
      "35/34 [==============================] - 20s - loss: 9.1020 - acc: 0.3455    \n",
      "Epoch 153/700\n",
      "35/34 [==============================] - 20s - loss: 9.1115 - acc: 0.3187    \n",
      "Epoch 154/700\n",
      "35/34 [==============================] - 17s - loss: 9.1431 - acc: 0.3126    \n",
      "Epoch 155/700\n",
      "35/34 [==============================] - 15s - loss: 8.9569 - acc: 0.3262    \n",
      "Epoch 156/700\n",
      "35/34 [==============================] - 20s - loss: 9.0972 - acc: 0.3232    \n",
      "Epoch 157/700\n",
      "35/34 [==============================] - 20s - loss: 9.2694 - acc: 0.3187    \n",
      "Epoch 158/700\n",
      "35/34 [==============================] - 20s - loss: 9.1731 - acc: 0.3295    \n",
      "Epoch 159/700\n",
      "35/34 [==============================] - 20s - loss: 8.9260 - acc: 0.3402    \n",
      "Epoch 160/700\n",
      "35/34 [==============================] - 20s - loss: 9.0381 - acc: 0.3375    \n",
      "Epoch 161/700\n",
      "35/34 [==============================] - 20s - loss: 9.0611 - acc: 0.3295    \n",
      "Epoch 162/700\n",
      "35/34 [==============================] - 20s - loss: 9.0304 - acc: 0.3223    \n",
      "Epoch 163/700\n",
      "35/34 [==============================] - 20s - loss: 8.9995 - acc: 0.3366    \n",
      "Epoch 164/700\n",
      "35/34 [==============================] - 18s - loss: 9.2172 - acc: 0.3229    \n",
      "Epoch 165/700\n",
      "35/34 [==============================] - 15s - loss: 9.8191 - acc: 0.2104    \n",
      "Epoch 166/700\n",
      "35/34 [==============================] - 20s - loss: 9.5096 - acc: 0.2357    \n",
      "Epoch 167/700\n",
      "35/34 [==============================] - 20s - loss: 9.3680 - acc: 0.3205    \n",
      "Epoch 168/700\n",
      "35/34 [==============================] - 19s - loss: 9.1026 - acc: 0.3366    \n",
      "Epoch 169/700\n",
      "35/34 [==============================] - 20s - loss: 9.5249 - acc: 0.3277    \n",
      "Epoch 170/700\n",
      "35/34 [==============================] - 20s - loss: 8.9993 - acc: 0.3402    \n",
      "Epoch 171/700\n",
      "35/34 [==============================] - 20s - loss: 9.3436 - acc: 0.2821    \n",
      "Epoch 172/700\n",
      "35/34 [==============================] - 20s - loss: 9.0273 - acc: 0.2937    \n",
      "Epoch 173/700\n",
      "35/34 [==============================] - 20s - loss: 9.2319 - acc: 0.3232    \n",
      "Epoch 174/700\n",
      "35/34 [==============================] - 19s - loss: 8.6888 - acc: 0.3365    \n",
      "Epoch 175/700\n",
      "35/34 [==============================] - 16s - loss: 9.6533 - acc: 0.1799    \n",
      "Epoch 176/700\n",
      "35/34 [==============================] - 18s - loss: 9.5404 - acc: 0.2214    \n",
      "Epoch 177/700\n",
      "35/34 [==============================] - 20s - loss: 9.1829 - acc: 0.2848    \n",
      "Epoch 178/700\n",
      "35/34 [==============================] - 19s - loss: 9.0856 - acc: 0.2991    \n",
      "Epoch 179/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/34 [==============================] - 19s - loss: 9.1009 - acc: 0.3330    \n",
      "Epoch 180/700\n",
      "35/34 [==============================] - 20s - loss: 9.5463 - acc: 0.3179    \n",
      "Epoch 181/700\n",
      "35/34 [==============================] - 20s - loss: 9.0215 - acc: 0.3214    \n",
      "Epoch 182/700\n",
      "35/34 [==============================] - 20s - loss: 9.1607 - acc: 0.3366    \n",
      "Epoch 183/700\n",
      "35/34 [==============================] - 19s - loss: 9.0390 - acc: 0.3259    \n",
      "Epoch 184/700\n",
      "35/34 [==============================] - 19s - loss: 8.7141 - acc: 0.3413    \n",
      "Epoch 185/700\n",
      "35/34 [==============================] - 17s - loss: 9.5744 - acc: 0.2806    \n",
      "Epoch 186/700\n",
      "35/34 [==============================] - 16s - loss: 8.8319 - acc: 0.2952    \n",
      "Epoch 187/700\n",
      "35/34 [==============================] - 20s - loss: 9.5165 - acc: 0.2964    \n",
      "Epoch 188/700\n",
      "35/34 [==============================] - 20s - loss: 9.0905 - acc: 0.3214    \n",
      "Epoch 189/700\n",
      "35/34 [==============================] - 20s - loss: 9.1260 - acc: 0.3384    \n",
      "Epoch 190/700\n",
      "35/34 [==============================] - 20s - loss: 8.9636 - acc: 0.3357    \n",
      "Epoch 191/700\n",
      "35/34 [==============================] - 20s - loss: 9.3067 - acc: 0.3295    \n",
      "Epoch 192/700\n",
      "35/34 [==============================] - 20s - loss: 8.8505 - acc: 0.3580    \n",
      "Epoch 193/700\n",
      "35/34 [==============================] - 20s - loss: 8.9345 - acc: 0.3446    \n",
      "Epoch 194/700\n",
      "35/34 [==============================] - 20s - loss: 9.2132 - acc: 0.3464    \n",
      "Epoch 195/700\n",
      "35/34 [==============================] - 17s - loss: 9.5452 - acc: 0.2765    \n",
      "Epoch 196/700\n",
      "35/34 [==============================] - 15s - loss: 9.5108 - acc: 0.2153    \n",
      "Epoch 197/700\n",
      "35/34 [==============================] - 19s - loss: 9.6437 - acc: 0.2759    \n",
      "Epoch 198/700\n",
      "35/34 [==============================] - 20s - loss: 9.3168 - acc: 0.3268    \n",
      "Epoch 199/700\n",
      "35/34 [==============================] - 19s - loss: 9.3710 - acc: 0.2982    \n",
      "Epoch 200/700\n",
      "35/34 [==============================] - 20s - loss: 9.5923 - acc: 0.2821    \n",
      "Epoch 201/700\n",
      "35/34 [==============================] - 19s - loss: 9.2336 - acc: 0.3143    \n",
      "Epoch 202/700\n",
      "35/34 [==============================] - 19s - loss: 9.0150 - acc: 0.3446    \n",
      "Epoch 203/700\n",
      "35/34 [==============================] - 20s - loss: 8.8391 - acc: 0.3187    \n",
      "Epoch 204/700\n",
      "35/34 [==============================] - 19s - loss: 9.4480 - acc: 0.3232    \n",
      "Epoch 205/700\n",
      "35/34 [==============================] - 18s - loss: 9.2357 - acc: 0.3086    \n",
      "Epoch 206/700\n",
      "35/34 [==============================] - 15s - loss: 9.2688 - acc: 0.2674    \n",
      "Epoch 207/700\n",
      "35/34 [==============================] - 19s - loss: 9.4090 - acc: 0.2946    \n",
      "Epoch 208/700\n",
      "35/34 [==============================] - 19s - loss: 8.6057 - acc: 0.3670    \n",
      "Epoch 209/700\n",
      "35/34 [==============================] - 20s - loss: 8.5149 - acc: 0.3732    \n",
      "Epoch 210/700\n",
      "35/34 [==============================] - 20s - loss: 9.2968 - acc: 0.3321    \n",
      "Epoch 211/700\n",
      "35/34 [==============================] - 19s - loss: 9.2976 - acc: 0.3393    \n",
      "Epoch 212/700\n",
      "35/34 [==============================] - 19s - loss: 8.7911 - acc: 0.3357    \n",
      "Epoch 213/700\n",
      "35/34 [==============================] - 19s - loss: 9.0097 - acc: 0.3509    \n",
      "Epoch 214/700\n",
      "35/34 [==============================] - 20s - loss: 9.0131 - acc: 0.3384    \n",
      "Epoch 215/700\n",
      "35/34 [==============================] - 18s - loss: 8.8814 - acc: 0.3630    \n",
      "Epoch 216/700\n",
      "35/34 [==============================] - 16s - loss: 9.0568 - acc: 0.2889    \n",
      "Epoch 217/700\n",
      "35/34 [==============================] - 17s - loss: 9.7898 - acc: 0.2182    \n",
      "Epoch 218/700\n",
      "35/34 [==============================] - 20s - loss: 9.3831 - acc: 0.2973    \n",
      "Epoch 219/700\n",
      "35/34 [==============================] - 19s - loss: 9.1781 - acc: 0.3366    \n",
      "Epoch 220/700\n",
      "35/34 [==============================] - 20s - loss: 9.5500 - acc: 0.2920    \n",
      "Epoch 221/700\n",
      "35/34 [==============================] - 19s - loss: 9.6681 - acc: 0.3000    \n",
      "Epoch 222/700\n",
      "35/34 [==============================] - 20s - loss: 9.1067 - acc: 0.3357    \n",
      "Epoch 223/700\n",
      "35/34 [==============================] - 20s - loss: 9.3240 - acc: 0.3250    \n",
      "Epoch 224/700\n",
      "35/34 [==============================] - 19s - loss: 8.8828 - acc: 0.3455    \n",
      "Epoch 225/700\n",
      "35/34 [==============================] - 19s - loss: 9.1524 - acc: 0.3455    \n",
      "Epoch 226/700\n",
      "35/34 [==============================] - 17s - loss: 9.1734 - acc: 0.2598    \n",
      "Epoch 227/700\n",
      "35/34 [==============================] - 16s - loss: 9.6304 - acc: 0.2069    \n",
      "Epoch 228/700\n",
      "35/34 [==============================] - 19s - loss: 9.4157 - acc: 0.3116    \n",
      "Epoch 229/700\n",
      "35/34 [==============================] - 19s - loss: 8.6739 - acc: 0.3598    \n",
      "Epoch 230/700\n",
      "35/34 [==============================] - 20s - loss: 8.8347 - acc: 0.3509    \n",
      "Epoch 231/700\n",
      "35/34 [==============================] - 19s - loss: 9.1691 - acc: 0.3607    \n",
      "Epoch 232/700\n",
      "35/34 [==============================] - 19s - loss: 9.0396 - acc: 0.3527    \n",
      "Epoch 233/700\n",
      "35/34 [==============================] - 20s - loss: 9.0305 - acc: 0.3402    \n",
      "Epoch 234/700\n",
      "35/34 [==============================] - 19s - loss: 9.2141 - acc: 0.3429    \n",
      "Epoch 235/700\n",
      "35/34 [==============================] - 20s - loss: 9.0172 - acc: 0.3384    \n",
      "Epoch 236/700\n",
      "35/34 [==============================] - 18s - loss: 9.0676 - acc: 0.3197    \n",
      "Epoch 237/700\n",
      "35/34 [==============================] - 15s - loss: 9.4271 - acc: 0.2972    \n",
      "Epoch 238/700\n",
      "35/34 [==============================] - 20s - loss: 9.3249 - acc: 0.2937    \n",
      "Epoch 239/700\n",
      "35/34 [==============================] - 19s - loss: 8.6365 - acc: 0.3616    \n",
      "Epoch 240/700\n",
      "35/34 [==============================] - 20s - loss: 9.0362 - acc: 0.3205    \n",
      "Epoch 241/700\n",
      "35/34 [==============================] - 19s - loss: 8.9139 - acc: 0.3393    \n",
      "Epoch 242/700\n",
      "35/34 [==============================] - 20s - loss: 8.9794 - acc: 0.3580    \n",
      "Epoch 243/700\n",
      "35/34 [==============================] - 19s - loss: 8.9662 - acc: 0.3455    \n",
      "Epoch 244/700\n",
      "35/34 [==============================] - 19s - loss: 8.8726 - acc: 0.3366    \n",
      "Epoch 245/700\n",
      "35/34 [==============================] - 20s - loss: 9.7177 - acc: 0.3170    \n",
      "Epoch 246/700\n",
      "35/34 [==============================] - 19s - loss: 9.7347 - acc: 0.3181    \n",
      "Epoch 247/700\n",
      "35/34 [==============================] - 16s - loss: 9.2915 - acc: 0.2899    \n",
      "Epoch 248/700\n",
      "35/34 [==============================] - 18s - loss: 9.3757 - acc: 0.2780    \n",
      "Epoch 249/700\n",
      "35/34 [==============================] - 19s - loss: 9.0551 - acc: 0.3429    \n",
      "Epoch 250/700\n",
      "35/34 [==============================] - 20s - loss: 9.0688 - acc: 0.3527    \n",
      "Epoch 251/700\n",
      "35/34 [==============================] - 19s - loss: 8.8567 - acc: 0.3473    \n",
      "Epoch 252/700\n",
      "35/34 [==============================] - 20s - loss: 9.0440 - acc: 0.3589    \n",
      "Epoch 253/700\n",
      "35/34 [==============================] - 19s - loss: 9.0952 - acc: 0.3545    \n",
      "Epoch 254/700\n",
      "35/34 [==============================] - 19s - loss: 9.0986 - acc: 0.3438    \n",
      "Epoch 255/700\n",
      "35/34 [==============================] - 19s - loss: 9.0406 - acc: 0.3536    \n",
      "Epoch 256/700\n",
      "35/34 [==============================] - 19s - loss: 8.4431 - acc: 0.3611    \n",
      "Epoch 257/700\n",
      "35/34 [==============================] - 17s - loss: 9.5993 - acc: 0.2711    \n",
      "Epoch 258/700\n",
      "35/34 [==============================] - 16s - loss: 9.1355 - acc: 0.2833    \n",
      "Epoch 259/700\n",
      "35/34 [==============================] - 19s - loss: 9.2373 - acc: 0.3500    \n",
      "Epoch 260/700\n",
      "35/34 [==============================] - 20s - loss: 9.0371 - acc: 0.3330    \n",
      "Epoch 261/700\n",
      "35/34 [==============================] - 19s - loss: 9.4033 - acc: 0.3402    \n",
      "Epoch 262/700\n",
      "35/34 [==============================] - 19s - loss: 8.9911 - acc: 0.3589    \n",
      "Epoch 263/700\n",
      "35/34 [==============================] - 20s - loss: 8.8781 - acc: 0.3580    \n",
      "Epoch 264/700\n",
      "35/34 [==============================] - 19s - loss: 9.5314 - acc: 0.3143    \n",
      "Epoch 265/700\n",
      "35/34 [==============================] - 19s - loss: 8.6848 - acc: 0.3884    \n",
      "Epoch 266/700\n",
      "35/34 [==============================] - 19s - loss: 8.9264 - acc: 0.3536    \n",
      "Epoch 267/700\n",
      "35/34 [==============================] - 17s - loss: 9.2006 - acc: 0.3143    \n",
      "Epoch 268/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/34 [==============================] - 15s - loss: 10.0935 - acc: 0.2084    \n",
      "Epoch 269/700\n",
      "35/34 [==============================] - 19s - loss: 9.0007 - acc: 0.3018    \n",
      "Epoch 270/700\n",
      "35/34 [==============================] - 20s - loss: 9.0860 - acc: 0.3286    \n",
      "Epoch 271/700\n",
      "35/34 [==============================] - 19s - loss: 8.9397 - acc: 0.3482    \n",
      "Epoch 272/700\n",
      "35/34 [==============================] - 19s - loss: 9.1122 - acc: 0.3491    \n",
      "Epoch 273/700\n",
      "35/34 [==============================] - 19s - loss: 9.2856 - acc: 0.3321    \n",
      "Epoch 274/700\n",
      "35/34 [==============================] - 19s - loss: 9.2005 - acc: 0.3491    \n",
      "Epoch 275/700\n",
      "35/34 [==============================] - 19s - loss: 8.8905 - acc: 0.3625    \n",
      "Epoch 276/700\n",
      "35/34 [==============================] - 20s - loss: 9.1143 - acc: 0.3473    \n",
      "Epoch 277/700\n",
      "35/34 [==============================] - 18s - loss: 9.5159 - acc: 0.3119    \n",
      "Epoch 278/700\n",
      "35/34 [==============================] - 15s - loss: 9.3428 - acc: 0.3084    \n",
      "Epoch 279/700\n",
      "35/34 [==============================] - 19s - loss: 9.2990 - acc: 0.2937    \n",
      "Epoch 280/700\n",
      "35/34 [==============================] - 19s - loss: 9.0565 - acc: 0.3402    \n",
      "Epoch 281/700\n",
      "35/34 [==============================] - 19s - loss: 9.5261 - acc: 0.3295    \n",
      "Epoch 282/700\n",
      "35/34 [==============================] - 20s - loss: 9.2317 - acc: 0.3464    \n",
      "Epoch 283/700\n",
      "35/34 [==============================] - 20s - loss: 9.5150 - acc: 0.3179    \n",
      "Epoch 284/700\n",
      "35/34 [==============================] - 19s - loss: 9.5455 - acc: 0.2795    \n",
      "Epoch 285/700\n",
      "35/34 [==============================] - 20s - loss: 9.4243 - acc: 0.3313    \n",
      "Epoch 286/700\n",
      "35/34 [==============================] - 20s - loss: 8.7164 - acc: 0.3759    \n",
      "Epoch 287/700\n",
      "35/34 [==============================] - 18s - loss: 8.8193 - acc: 0.3504    \n",
      "Epoch 288/700\n",
      "35/34 [==============================] - 16s - loss: 9.7591 - acc: 0.2943    \n",
      "Epoch 289/700\n",
      "35/34 [==============================] - 17s - loss: 9.4162 - acc: 0.2556    \n",
      "Epoch 290/700\n",
      "35/34 [==============================] - 19s - loss: 9.1352 - acc: 0.3384    \n",
      "Epoch 291/700\n",
      "35/34 [==============================] - 20s - loss: 9.2269 - acc: 0.3402    \n",
      "Epoch 292/700\n",
      "35/34 [==============================] - 19s - loss: 8.8218 - acc: 0.3509    \n",
      "Epoch 293/700\n",
      "35/34 [==============================] - 20s - loss: 9.4159 - acc: 0.3402    \n",
      "Epoch 294/700\n",
      "35/34 [==============================] - 19s - loss: 9.1415 - acc: 0.3589    \n",
      "Epoch 295/700\n",
      "35/34 [==============================] - 19s - loss: 9.1801 - acc: 0.3500    \n",
      "Epoch 296/700\n",
      "35/34 [==============================] - 19s - loss: 9.2101 - acc: 0.3393    \n",
      "Epoch 297/700\n",
      "35/34 [==============================] - 20s - loss: 8.9993 - acc: 0.3607    \n",
      "Epoch 298/700\n",
      "35/34 [==============================] - 17s - loss: 9.3072 - acc: 0.2947    \n",
      "Epoch 299/700\n",
      "35/34 [==============================] - 15s - loss: 9.2994 - acc: 0.2622    \n",
      "Epoch 300/700\n",
      "35/34 [==============================] - 19s - loss: 9.6349 - acc: 0.3018    \n",
      "Epoch 301/700\n",
      "35/34 [==============================] - 20s - loss: 8.9871 - acc: 0.3268    \n",
      "Epoch 302/700\n",
      "35/34 [==============================] - 19s - loss: 8.8991 - acc: 0.3509    \n",
      "Epoch 303/700\n",
      "35/34 [==============================] - 19s - loss: 9.1391 - acc: 0.3464    \n",
      "Epoch 304/700\n",
      "35/34 [==============================] - 19s - loss: 8.9007 - acc: 0.3652    \n",
      "Epoch 305/700\n",
      "35/34 [==============================] - 19s - loss: 8.8016 - acc: 0.3750    \n",
      "Epoch 306/700\n",
      "35/34 [==============================] - 19s - loss: 9.0636 - acc: 0.3554    \n",
      "Epoch 307/700\n",
      "35/34 [==============================] - 19s - loss: 9.3436 - acc: 0.3429    \n",
      "Epoch 308/700\n",
      "35/34 [==============================] - 18s - loss: 8.7743 - acc: 0.3830    \n",
      "Epoch 309/700\n",
      "35/34 [==============================] - 14s - loss: 9.5810 - acc: 0.2483    \n",
      "Epoch 310/700\n",
      "35/34 [==============================] - 19s - loss: 9.2619 - acc: 0.3018    \n",
      "Epoch 311/700\n",
      "35/34 [==============================] - 20s - loss: 9.6264 - acc: 0.3036    \n",
      "Epoch 312/700\n",
      "35/34 [==============================] - 20s - loss: 9.0765 - acc: 0.3679    \n",
      "Epoch 313/700\n",
      "35/34 [==============================] - 19s - loss: 9.1608 - acc: 0.3366    \n",
      "Epoch 314/700\n",
      "35/34 [==============================] - 19s - loss: 9.3586 - acc: 0.3250    \n",
      "Epoch 315/700\n",
      "35/34 [==============================] - 19s - loss: 9.2287 - acc: 0.3339    \n",
      "Epoch 316/700\n",
      "35/34 [==============================] - 20s - loss: 9.4729 - acc: 0.3259    \n",
      "Epoch 317/700\n",
      "35/34 [==============================] - 19s - loss: 8.8474 - acc: 0.3732    \n",
      "Epoch 318/700\n",
      "35/34 [==============================] - 18s - loss: 8.8973 - acc: 0.3609    \n",
      "Epoch 319/700\n",
      "35/34 [==============================] - 16s - loss: 9.1751 - acc: 0.2680    \n",
      "Epoch 320/700\n",
      "35/34 [==============================] - 18s - loss: 9.5396 - acc: 0.2640    \n",
      "Epoch 321/700\n",
      "35/34 [==============================] - 19s - loss: 9.1705 - acc: 0.3295    \n",
      "Epoch 322/700\n",
      "35/34 [==============================] - 20s - loss: 8.9855 - acc: 0.3759    \n",
      "Epoch 323/700\n",
      "35/34 [==============================] - 19s - loss: 9.0239 - acc: 0.3598    \n",
      "Epoch 324/700\n",
      "35/34 [==============================] - 19s - loss: 8.9578 - acc: 0.3420    \n",
      "Epoch 325/700\n",
      "35/34 [==============================] - 20s - loss: 8.9170 - acc: 0.3714    \n",
      "Epoch 326/700\n",
      "35/34 [==============================] - 19s - loss: 8.9334 - acc: 0.3643    \n",
      "Epoch 327/700\n",
      "35/34 [==============================] - 19s - loss: 9.5130 - acc: 0.3509    \n",
      "Epoch 328/700\n",
      "35/34 [==============================] - 19s - loss: 8.9627 - acc: 0.3484    \n",
      "Epoch 329/700\n",
      "35/34 [==============================] - 17s - loss: 9.4056 - acc: 0.2922    \n",
      "Epoch 330/700\n",
      "35/34 [==============================] - 16s - loss: 9.5975 - acc: 0.2662    \n",
      "Epoch 331/700\n",
      "35/34 [==============================] - 19s - loss: 9.4316 - acc: 0.3214    \n",
      "Epoch 332/700\n",
      "35/34 [==============================] - 19s - loss: 8.9989 - acc: 0.3571    \n",
      "Epoch 333/700\n",
      "35/34 [==============================] - 19s - loss: 8.9029 - acc: 0.3714    \n",
      "Epoch 334/700\n",
      "35/34 [==============================] - 19s - loss: 9.3183 - acc: 0.3161    \n",
      "Epoch 335/700\n",
      "35/34 [==============================] - 19s - loss: 9.0402 - acc: 0.3598    \n",
      "Epoch 336/700\n",
      "35/34 [==============================] - 19s - loss: 8.9210 - acc: 0.3741    \n",
      "Epoch 337/700\n",
      "35/34 [==============================] - 20s - loss: 8.9309 - acc: 0.3670    \n",
      "Epoch 338/700\n",
      "35/34 [==============================] - 19s - loss: 8.7804 - acc: 0.3821    \n",
      "Epoch 339/700\n",
      "35/34 [==============================] - 17s - loss: 9.4604 - acc: 0.3189    \n",
      "Epoch 340/700\n",
      "35/34 [==============================] - 15s - loss: 9.6010 - acc: 0.2566    \n",
      "Epoch 341/700\n",
      "35/34 [==============================] - 20s - loss: 9.6362 - acc: 0.3071    \n",
      "Epoch 342/700\n",
      "35/34 [==============================] - 19s - loss: 8.9873 - acc: 0.3643    \n",
      "Epoch 343/700\n",
      "35/34 [==============================] - 19s - loss: 9.3944 - acc: 0.3562    \n",
      "Epoch 344/700\n",
      "35/34 [==============================] - 19s - loss: 9.1135 - acc: 0.3714    \n",
      "Epoch 345/700\n",
      "35/34 [==============================] - 19s - loss: 8.7605 - acc: 0.3705    \n",
      "Epoch 346/700\n",
      "35/34 [==============================] - 20s - loss: 8.9617 - acc: 0.3500    \n",
      "Epoch 347/700\n",
      "35/34 [==============================] - 20s - loss: 9.0431 - acc: 0.3625    \n",
      "Epoch 348/700\n",
      "35/34 [==============================] - 19s - loss: 9.0780 - acc: 0.3580    \n",
      "Epoch 349/700\n",
      "35/34 [==============================] - 18s - loss: 8.6761 - acc: 0.3653    \n",
      "Epoch 350/700\n",
      "35/34 [==============================] - 14s - loss: 9.2195 - acc: 0.2880    \n",
      "Epoch 351/700\n",
      "35/34 [==============================] - 20s - loss: 9.3724 - acc: 0.2884    \n",
      "Epoch 352/700\n",
      "35/34 [==============================] - 19s - loss: 9.2621 - acc: 0.3429    \n",
      "Epoch 353/700\n",
      "35/34 [==============================] - 19s - loss: 9.2996 - acc: 0.3259    \n",
      "Epoch 354/700\n",
      "35/34 [==============================] - 19s - loss: 8.8754 - acc: 0.3554    \n",
      "Epoch 355/700\n",
      "35/34 [==============================] - 19s - loss: 9.2657 - acc: 0.3250    \n",
      "Epoch 356/700\n",
      "35/34 [==============================] - 20s - loss: 8.7954 - acc: 0.3509    \n",
      "Epoch 357/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/34 [==============================] - 20s - loss: 8.7719 - acc: 0.3696    \n",
      "Epoch 358/700\n",
      "35/34 [==============================] - 19s - loss: 9.2297 - acc: 0.3313    \n",
      "Epoch 359/700\n",
      "35/34 [==============================] - 18s - loss: 8.9131 - acc: 0.3629    \n",
      "Epoch 360/700\n",
      "35/34 [==============================] - 16s - loss: 9.1334 - acc: 0.3422    \n",
      "Epoch 361/700\n",
      "35/34 [==============================] - 17s - loss: 9.1851 - acc: 0.3050    \n",
      "Epoch 362/700\n",
      "35/34 [==============================] - 19s - loss: 9.2092 - acc: 0.3500    \n",
      "Epoch 363/700\n",
      "35/34 [==============================] - 20s - loss: 9.2775 - acc: 0.3589    \n",
      "Epoch 364/700\n",
      "35/34 [==============================] - 20s - loss: 8.7088 - acc: 0.3830    \n",
      "Epoch 365/700\n",
      "35/34 [==============================] - 19s - loss: 9.0057 - acc: 0.3714    \n",
      "Epoch 366/700\n",
      "35/34 [==============================] - 19s - loss: 9.1425 - acc: 0.3455    \n",
      "Epoch 367/700\n",
      "35/34 [==============================] - 19s - loss: 9.0842 - acc: 0.3670    \n",
      "Epoch 368/700\n",
      "35/34 [==============================] - 20s - loss: 9.1107 - acc: 0.3661    \n",
      "Epoch 369/700\n",
      "35/34 [==============================] - 19s - loss: 9.1304 - acc: 0.3732    \n",
      "Epoch 370/700\n",
      "35/34 [==============================] - 17s - loss: 9.2238 - acc: 0.3148    \n",
      "Epoch 371/700\n",
      "35/34 [==============================] - 16s - loss: 9.6616 - acc: 0.2470    \n",
      "Epoch 372/700\n",
      "35/34 [==============================] - 19s - loss: 8.8494 - acc: 0.3554    \n",
      "Epoch 373/700\n",
      "35/34 [==============================] - 19s - loss: 9.0771 - acc: 0.3562    \n",
      "Epoch 374/700\n",
      "35/34 [==============================] - 19s - loss: 9.2687 - acc: 0.3536    \n",
      "Epoch 375/700\n",
      "35/34 [==============================] - 19s - loss: 8.8464 - acc: 0.3812    \n",
      "Epoch 376/700\n",
      "35/34 [==============================] - 20s - loss: 9.0567 - acc: 0.3571    \n",
      "Epoch 377/700\n",
      "35/34 [==============================] - 19s - loss: 9.6240 - acc: 0.3357    \n",
      "Epoch 378/700\n",
      "35/34 [==============================] - 20s - loss: 9.0018 - acc: 0.3625    \n",
      "Epoch 379/700\n",
      "35/34 [==============================] - 19s - loss: 9.4833 - acc: 0.3402    \n",
      "Epoch 380/700\n",
      "35/34 [==============================] - 18s - loss: 9.2354 - acc: 0.3110    \n",
      "Epoch 381/700\n",
      "35/34 [==============================] - 14s - loss: 9.5546 - acc: 0.2033    \n",
      "Epoch 382/700\n",
      "35/34 [==============================] - 20s - loss: 9.3371 - acc: 0.2661    \n",
      "Epoch 383/700\n",
      "35/34 [==============================] - 20s - loss: 9.1806 - acc: 0.3366    \n",
      "Epoch 384/700\n",
      "35/34 [==============================] - 19s - loss: 8.9866 - acc: 0.3330    \n",
      "Epoch 385/700\n",
      "35/34 [==============================] - 19s - loss: 9.2528 - acc: 0.3482    \n",
      "Epoch 386/700\n",
      "35/34 [==============================] - 20s - loss: 9.3339 - acc: 0.3304    \n",
      "Epoch 387/700\n",
      "35/34 [==============================] - 20s - loss: 9.1473 - acc: 0.3455    \n",
      "Epoch 388/700\n",
      "35/34 [==============================] - 20s - loss: 9.2467 - acc: 0.3571    \n",
      "Epoch 389/700\n",
      "35/34 [==============================] - 19s - loss: 9.1147 - acc: 0.3223    \n",
      "Epoch 390/700\n",
      "35/34 [==============================] - 18s - loss: 9.2495 - acc: 0.3311    \n",
      "Epoch 391/700\n",
      "35/34 [==============================] - 15s - loss: 9.4777 - acc: 0.2715    \n",
      "Epoch 392/700\n",
      "35/34 [==============================] - 18s - loss: 9.4454 - acc: 0.2822    \n",
      "Epoch 393/700\n",
      "35/34 [==============================] - 20s - loss: 9.1611 - acc: 0.3339    \n",
      "Epoch 394/700\n",
      "35/34 [==============================] - 19s - loss: 9.1930 - acc: 0.3545    \n",
      "Epoch 395/700\n",
      "35/34 [==============================] - 20s - loss: 9.1466 - acc: 0.3598    \n",
      "Epoch 396/700\n",
      "35/34 [==============================] - 19s - loss: 9.0219 - acc: 0.3607    \n",
      "Epoch 397/700\n",
      "35/34 [==============================] - 19s - loss: 9.1170 - acc: 0.3393    \n",
      "Epoch 398/700\n",
      "35/34 [==============================] - 20s - loss: 9.5188 - acc: 0.3277    \n",
      "Epoch 399/700\n",
      "35/34 [==============================] - 19s - loss: 9.5836 - acc: 0.3107    \n",
      "Epoch 400/700\n",
      "35/34 [==============================] - 19s - loss: 9.1295 - acc: 0.3690    \n",
      "Epoch 401/700\n",
      "35/34 [==============================] - 17s - loss: 9.2811 - acc: 0.2946    \n",
      "Epoch 402/700\n",
      "35/34 [==============================] - 16s - loss: 9.9959 - acc: 0.1935     \n",
      "Epoch 403/700\n",
      "35/34 [==============================] - 19s - loss: 10.0762 - acc: 0.2491    \n",
      "Epoch 404/700\n",
      "35/34 [==============================] - 19s - loss: 9.1174 - acc: 0.3402    \n",
      "Epoch 405/700\n",
      "35/34 [==============================] - 19s - loss: 9.1013 - acc: 0.3411    \n",
      "Epoch 406/700\n",
      "35/34 [==============================] - 19s - loss: 9.0387 - acc: 0.3330    \n",
      "Epoch 407/700\n",
      "35/34 [==============================] - 19s - loss: 9.1935 - acc: 0.3295    \n",
      "Epoch 408/700\n",
      "35/34 [==============================] - 19s - loss: 9.0427 - acc: 0.3598    \n",
      "Epoch 409/700\n",
      "35/34 [==============================] - 19s - loss: 9.1752 - acc: 0.3518    \n",
      "Epoch 410/700\n",
      "35/34 [==============================] - 20s - loss: 8.9621 - acc: 0.3571    \n",
      "Epoch 411/700\n",
      "35/34 [==============================] - 17s - loss: 9.7761 - acc: 0.2839    \n",
      "Epoch 412/700\n",
      "35/34 [==============================] - 15s - loss: 9.4587 - acc: 0.2596    \n",
      "Epoch 413/700\n",
      "35/34 [==============================] - 19s - loss: 8.9489 - acc: 0.3393    \n",
      "Epoch 414/700\n",
      "35/34 [==============================] - 19s - loss: 9.5649 - acc: 0.2946    \n",
      "Epoch 415/700\n",
      "35/34 [==============================] - 19s - loss: 9.4647 - acc: 0.3509    \n",
      "Epoch 416/700\n",
      "35/34 [==============================] - 19s - loss: 9.1403 - acc: 0.3500    \n",
      "Epoch 417/700\n",
      "35/34 [==============================] - 20s - loss: 9.4011 - acc: 0.3277    \n",
      "Epoch 418/700\n",
      "35/34 [==============================] - 19s - loss: 8.7152 - acc: 0.3643    \n",
      "Epoch 419/700\n",
      "35/34 [==============================] - 19s - loss: 8.9698 - acc: 0.3616    \n",
      "Epoch 420/700\n",
      "35/34 [==============================] - 19s - loss: 9.4957 - acc: 0.3259    \n",
      "Epoch 421/700\n",
      "35/34 [==============================] - 18s - loss: 8.9760 - acc: 0.3412    \n",
      "Epoch 422/700\n",
      "35/34 [==============================] - 15s - loss: 9.4242 - acc: 0.2843    \n",
      "Epoch 423/700\n",
      "35/34 [==============================] - 19s - loss: 9.1953 - acc: 0.2937    \n",
      "Epoch 424/700\n",
      "35/34 [==============================] - 19s - loss: 9.2589 - acc: 0.3384    \n",
      "Epoch 425/700\n",
      "35/34 [==============================] - 19s - loss: 9.4526 - acc: 0.3384    \n",
      "Epoch 426/700\n",
      "35/34 [==============================] - 19s - loss: 8.7491 - acc: 0.3768    \n",
      "Epoch 427/700\n",
      "35/34 [==============================] - 19s - loss: 9.0214 - acc: 0.3696    \n",
      "Epoch 428/700\n",
      "35/34 [==============================] - 19s - loss: 8.3568 - acc: 0.4071    \n",
      "Epoch 429/700\n",
      "35/34 [==============================] - 19s - loss: 8.4203 - acc: 0.3732    \n",
      "Epoch 430/700\n",
      "35/34 [==============================] - 19s - loss: 8.6660 - acc: 0.3777    \n",
      "Epoch 431/700\n",
      "35/34 [==============================] - 19s - loss: 9.1467 - acc: 0.3493    \n",
      "Epoch 432/700\n",
      "35/34 [==============================] - 16s - loss: 8.9474 - acc: 0.3151    \n",
      "Epoch 433/700\n",
      "35/34 [==============================] - 17s - loss: 9.7114 - acc: 0.2609    \n",
      "Epoch 434/700\n",
      "35/34 [==============================] - 19s - loss: 9.2930 - acc: 0.3277    \n",
      "Epoch 435/700\n",
      "35/34 [==============================] - 20s - loss: 9.2657 - acc: 0.3304    \n",
      "Epoch 436/700\n",
      "35/34 [==============================] - 19s - loss: 9.3125 - acc: 0.3536    \n",
      "Epoch 437/700\n",
      "35/34 [==============================] - 19s - loss: 9.0297 - acc: 0.3304    \n",
      "Epoch 438/700\n",
      "35/34 [==============================] - 19s - loss: 9.1736 - acc: 0.3473    \n",
      "Epoch 439/700\n",
      "35/34 [==============================] - 19s - loss: 8.8405 - acc: 0.3884    \n",
      "Epoch 440/700\n",
      "35/34 [==============================] - 19s - loss: 8.8649 - acc: 0.3741    \n",
      "Epoch 441/700\n",
      "35/34 [==============================] - 19s - loss: 9.2650 - acc: 0.3634    \n",
      "Epoch 442/700\n",
      "35/34 [==============================] - 17s - loss: 9.3161 - acc: 0.2923    \n",
      "Epoch 443/700\n",
      "35/34 [==============================] - 15s - loss: 9.8061 - acc: 0.1940    \n",
      "Epoch 444/700\n",
      "35/34 [==============================] - 20s - loss: 9.2682 - acc: 0.3045    \n",
      "Epoch 445/700\n",
      "35/34 [==============================] - 19s - loss: 9.2288 - acc: 0.3179    \n",
      "Epoch 446/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/34 [==============================] - 19s - loss: 9.2841 - acc: 0.3295    \n",
      "Epoch 447/700\n",
      "35/34 [==============================] - 19s - loss: 8.8789 - acc: 0.3795    \n",
      "Epoch 448/700\n",
      "35/34 [==============================] - 19s - loss: 9.1325 - acc: 0.3464    \n",
      "Epoch 449/700\n",
      "35/34 [==============================] - 19s - loss: 8.9753 - acc: 0.3661    \n",
      "Epoch 450/700\n",
      "35/34 [==============================] - 19s - loss: 9.1936 - acc: 0.3402    \n",
      "Epoch 451/700\n",
      "35/34 [==============================] - 20s - loss: 8.9170 - acc: 0.3795    \n",
      "Epoch 452/700\n",
      "35/34 [==============================] - 18s - loss: 9.6560 - acc: 0.2812    \n",
      "Epoch 453/700\n",
      "35/34 [==============================] - 15s - loss: 9.3996 - acc: 0.2956    \n",
      "Epoch 454/700\n",
      "35/34 [==============================] - 19s - loss: 8.9762 - acc: 0.3473    \n",
      "Epoch 455/700\n",
      "35/34 [==============================] - 19s - loss: 8.7468 - acc: 0.3688    \n",
      "Epoch 456/700\n",
      "35/34 [==============================] - 19s - loss: 9.2547 - acc: 0.3696    \n",
      "Epoch 457/700\n",
      "35/34 [==============================] - 19s - loss: 9.3702 - acc: 0.3616    \n",
      "Epoch 458/700\n",
      "35/34 [==============================] - 20s - loss: 9.0934 - acc: 0.3598    \n",
      "Epoch 459/700\n",
      "35/34 [==============================] - 19s - loss: 9.3512 - acc: 0.3580    \n",
      "Epoch 460/700\n",
      "35/34 [==============================] - 19s - loss: 9.2371 - acc: 0.3348    \n",
      "Epoch 461/700\n",
      "35/34 [==============================] - 20s - loss: 8.5827 - acc: 0.4062    \n",
      "Epoch 462/700\n",
      "35/34 [==============================] - 18s - loss: 8.6447 - acc: 0.3815    \n",
      "Epoch 463/700\n",
      "35/34 [==============================] - 16s - loss: 8.6998 - acc: 0.3390    \n",
      "Epoch 464/700\n",
      "35/34 [==============================] - 18s - loss: 9.7955 - acc: 0.2003    \n",
      "Epoch 465/700\n",
      "35/34 [==============================] - 19s - loss: 9.0673 - acc: 0.3375    \n",
      "Epoch 466/700\n",
      "35/34 [==============================] - 19s - loss: 9.4004 - acc: 0.3366    \n",
      "Epoch 467/700\n",
      "35/34 [==============================] - 19s - loss: 9.2196 - acc: 0.3393    \n",
      "Epoch 468/700\n",
      "35/34 [==============================] - 19s - loss: 8.9061 - acc: 0.3491    \n",
      "Epoch 469/700\n",
      "35/34 [==============================] - 20s - loss: 8.9156 - acc: 0.3580    \n",
      "Epoch 470/700\n",
      "35/34 [==============================] - 19s - loss: 9.0780 - acc: 0.3357    \n",
      "Epoch 471/700\n",
      "35/34 [==============================] - 19s - loss: 8.9403 - acc: 0.3741    \n",
      "Epoch 472/700\n",
      "35/34 [==============================] - 19s - loss: 9.4612 - acc: 0.3155    \n",
      "Epoch 473/700\n",
      "35/34 [==============================] - 16s - loss: 9.6130 - acc: 0.2938    \n",
      "Epoch 474/700\n",
      "35/34 [==============================] - 17s - loss: 9.4669 - acc: 0.2595    \n",
      "Epoch 475/700\n",
      "35/34 [==============================] - 19s - loss: 9.4515 - acc: 0.3063    \n",
      "Epoch 476/700\n",
      "35/34 [==============================] - 19s - loss: 9.2709 - acc: 0.3286    \n",
      "Epoch 477/700\n",
      "35/34 [==============================] - 19s - loss: 8.9891 - acc: 0.3598    \n",
      "Epoch 478/700\n",
      "35/34 [==============================] - 19s - loss: 9.1247 - acc: 0.3652    \n",
      "Epoch 479/700\n",
      "35/34 [==============================] - 20s - loss: 9.1726 - acc: 0.3518    \n",
      "Epoch 480/700\n",
      "35/34 [==============================] - 19s - loss: 8.7924 - acc: 0.3777    \n",
      "Epoch 481/700\n",
      "35/34 [==============================] - 19s - loss: 8.9771 - acc: 0.3536    \n",
      "Epoch 482/700\n",
      "35/34 [==============================] - 19s - loss: 8.9488 - acc: 0.3750    \n",
      "Epoch 483/700\n",
      "35/34 [==============================] - 17s - loss: 8.9142 - acc: 0.3548    \n",
      "Epoch 484/700\n",
      "35/34 [==============================] - 16s - loss: 9.2790 - acc: 0.2448    \n",
      "Epoch 485/700\n",
      "35/34 [==============================] - 19s - loss: 9.3644 - acc: 0.2786    \n",
      "Epoch 486/700\n",
      "35/34 [==============================] - 19s - loss: 8.9617 - acc: 0.3536    \n",
      "Epoch 487/700\n",
      "35/34 [==============================] - 19s - loss: 9.4685 - acc: 0.3330    \n",
      "Epoch 488/700\n",
      "35/34 [==============================] - 19s - loss: 9.0937 - acc: 0.3509    \n",
      "Epoch 489/700\n",
      "35/34 [==============================] - 19s - loss: 9.1771 - acc: 0.3527    \n",
      "Epoch 490/700\n",
      "35/34 [==============================] - 20s - loss: 9.0127 - acc: 0.3607    \n",
      "Epoch 491/700\n",
      "35/34 [==============================] - 19s - loss: 9.2217 - acc: 0.3429    \n",
      "Epoch 492/700\n",
      "35/34 [==============================] - 19s - loss: 9.1104 - acc: 0.3545    \n",
      "Epoch 493/700\n",
      "35/34 [==============================] - 18s - loss: 8.9805 - acc: 0.3382    \n",
      "Epoch 494/700\n",
      "35/34 [==============================] - 14s - loss: 9.2064 - acc: 0.3016    \n",
      "Epoch 495/700\n",
      "35/34 [==============================] - 20s - loss: 9.5886 - acc: 0.2509    \n",
      "Epoch 496/700\n",
      "35/34 [==============================] - 19s - loss: 9.1684 - acc: 0.3375    \n",
      "Epoch 497/700\n",
      "35/34 [==============================] - 19s - loss: 9.5963 - acc: 0.3348    \n",
      "Epoch 498/700\n",
      "35/34 [==============================] - 19s - loss: 8.8120 - acc: 0.3670    \n",
      "Epoch 499/700\n",
      "35/34 [==============================] - 19s - loss: 9.1864 - acc: 0.3366    \n",
      "Epoch 500/700\n",
      "35/34 [==============================] - 19s - loss: 8.9914 - acc: 0.3661    \n",
      "Epoch 501/700\n",
      "35/34 [==============================] - 19s - loss: 9.3380 - acc: 0.3518    \n",
      "Epoch 502/700\n",
      "35/34 [==============================] - 19s - loss: 9.0802 - acc: 0.3598    \n",
      "Epoch 503/700\n",
      "35/34 [==============================] - 19s - loss: 9.0080 - acc: 0.3685    \n",
      "Epoch 504/700\n",
      "35/34 [==============================] - 16s - loss: 8.9622 - acc: 0.2910    \n",
      "Epoch 505/700\n",
      "35/34 [==============================] - 17s - loss: 9.1897 - acc: 0.2349    \n",
      "Epoch 506/700\n",
      "35/34 [==============================] - 19s - loss: 9.3719 - acc: 0.3054    \n",
      "Epoch 507/700\n",
      "35/34 [==============================] - 19s - loss: 9.2339 - acc: 0.3464    \n",
      "Epoch 508/700\n",
      "35/34 [==============================] - 19s - loss: 9.0785 - acc: 0.3696    \n",
      "Epoch 509/700\n",
      "35/34 [==============================] - 19s - loss: 9.0947 - acc: 0.3830    \n",
      "Epoch 510/700\n",
      "35/34 [==============================] - 20s - loss: 8.6834 - acc: 0.3688    \n",
      "Epoch 511/700\n",
      "35/34 [==============================] - 19s - loss: 8.9044 - acc: 0.3812    \n",
      "Epoch 512/700\n",
      "35/34 [==============================] - 19s - loss: 8.7683 - acc: 0.3696    \n",
      "Epoch 513/700\n",
      "35/34 [==============================] - 19s - loss: 9.0398 - acc: 0.3634    \n",
      "Epoch 514/700\n",
      "35/34 [==============================] - 17s - loss: 9.1639 - acc: 0.3254    \n",
      "Epoch 515/700\n",
      "35/34 [==============================] - 15s - loss: 9.3085 - acc: 0.2856    \n",
      "Epoch 516/700\n",
      "35/34 [==============================] - 19s - loss: 9.1661 - acc: 0.3339    \n",
      "Epoch 517/700\n",
      "35/34 [==============================] - 19s - loss: 8.6423 - acc: 0.3562    \n",
      "Epoch 518/700\n",
      "35/34 [==============================] - 19s - loss: 9.2314 - acc: 0.3455    \n",
      "Epoch 519/700\n",
      "35/34 [==============================] - 19s - loss: 8.8021 - acc: 0.3732    \n",
      "Epoch 520/700\n",
      "35/34 [==============================] - 20s - loss: 9.3407 - acc: 0.3268    \n",
      "Epoch 521/700\n",
      "35/34 [==============================] - 19s - loss: 9.3288 - acc: 0.3330    \n",
      "Epoch 522/700\n",
      "10/34 [=======>......................] - ETA: 13s - loss: 9.0895 - acc: 0.3688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-87:\n",
      "Process Process-95:\n",
      "Process Process-94:\n",
      "Process Process-83:\n",
      "Traceback (most recent call last):\n",
      "Process Process-96:\n",
      "Process Process-81:\n",
      "Process Process-93:\n",
      "Process Process-92:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-86:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-82:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 569, in data_generator_task\n",
      "    self.queue.put(generator_output)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7bd85e78f908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit_generator(datagen.flow(x, y, batch_size=batch_size),\n\u001b[0;32m----> 3\u001b[0;31m                     steps_per_epoch=len(x) / batch_size * 2, epochs=700, use_multiprocessing=True, workers=20)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit_generator(datagen.flow(x, y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x) / batch_size * 2, epochs=700, use_multiprocessing=True, workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.531507627813665, 0.31531531547640895]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate_generator(test_datagen.flow(x, y, batch_size=32), steps=len(x) / 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander_cls_train.csv : 11.5315075385, 0.315315315369\n",
      "Alexander_cls_test.csv : 13.6336499102, 0.181531531545\n",
      "Alexander_cls_test1.csv : 11.6636511485, 0.306306306414\n",
      "Alexander_cls_test2.csv : 14.4012747825, 0.131531531746\n",
      "Alexander_cls_test3.csv : 13.5366840569, 0.187387387495\n",
      "Alexander_cls_test4.csv : 14.9329902632, 0.100900900955\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "#     featurewise_std_normalization=True\n",
    ")\n",
    "\n",
    "test_datagen.fit(x)\n",
    "\n",
    "test_paths = ['Alexander_cls_train.csv',\n",
    "             'Alexander_cls_test.csv',\n",
    "             'Alexander_cls_test1.csv',\n",
    "             'Alexander_cls_test2.csv',\n",
    "             'Alexander_cls_test3.csv',\n",
    "             'Alexander_cls_test4.csv']\n",
    "\n",
    "for test_path in test_paths:\n",
    "    x_test, y_test, num_classes = process_file(test_path)\n",
    "#     test_datagen.fit(x_test)\n",
    "    score = model.evaluate_generator(test_datagen.flow(x_test, y_test, batch_size=32), steps=len(x_test) / 32)\n",
    "    print(test_path + ' : ' + ', '.join(str(x) for x in score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x, y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(np.argmax(y_predict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_133 (Conv2D)          (None, 198, 198, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 99, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 97, 97, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 46, 46, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 21, 21, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                512010    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,061,834\n",
      "Trainable params: 2,061,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   500 samples   (,   )\n",
    "#  50  ,  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
