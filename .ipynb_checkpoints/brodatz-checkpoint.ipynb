{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove prefixes\n",
    "import os\n",
    "path = '/Users/take5v/Repository/data/data4stas/01_data_cls/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        x.append(cv2.imread(row['FilePath'], cv2.IMREAD_GRAYSCALE))\n",
    "        y.append(float(row['ClassId']))\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "\n",
    "    x = x.reshape(x.shape + (-1,))\n",
    "    y = y - 1\n",
    "    y = keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    return x, y, num_classes\n",
    "            \n",
    "\n",
    "def process_line(line):\n",
    "    pass\n",
    "\n",
    "def generate_arrays_from_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            # create numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x1, x2, y = process_line(line)\n",
    "            yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y, num_classes = process_file('Alexander_cls_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/keras/preprocessing/image.py:653: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (555, 200, 200, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "datagen.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 200x200 grayscale images -> (200, 200, 1) tensors.\n",
    "# this applies 8 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(200, 200, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(128, (2, 2), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(256, (2, 2), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(2048, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model.add(Dense(num_classes, kernel_regularizer=regularizers.l2(0.01), activation='softmax'), )\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x, y, batch_size=8, epochs=10, validation_data=(x_train, y_train))\n",
    "model.fit(x, y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17/17 [==============================] - 14s - loss: 12.8359 - acc: 0.0037    \n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 12s - loss: 11.7696 - acc: 0.0037    \n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 12s - loss: 11.2831 - acc: 0.0074    \n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 13s - loss: 10.9030 - acc: 0.0055    \n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 12s - loss: 10.6714 - acc: 0.0147    \n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 12s - loss: 9.9886 - acc: 0.0037    \n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 14s - loss: 10.1983 - acc: 0.0092    \n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 13s - loss: 9.9939 - acc: 0.0184     \n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 12s - loss: 10.4264 - acc: 0.0107    \n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 12s - loss: 9.9599 - acc: 0.0184    \n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 12s - loss: 9.7679 - acc: 0.0111    \n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 13s - loss: 10.2271 - acc: 0.0129    \n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 13s - loss: 9.8363 - acc: 0.0240    \n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 12s - loss: 10.1242 - acc: 0.0258    \n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 12s - loss: 10.3357 - acc: 0.0276    \n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 12s - loss: 10.5171 - acc: 0.0424    \n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 12s - loss: 10.0946 - acc: 0.0420    \n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 12s - loss: 9.2689 - acc: 0.0276    \n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 13s - loss: 10.4076 - acc: 0.0312    \n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 12s - loss: 10.0588 - acc: 0.0402    \n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 13s - loss: 9.5937 - acc: 0.0512    \n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 12s - loss: 9.0529 - acc: 0.0645    \n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 12s - loss: 9.9386 - acc: 0.0626    \n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 12s - loss: 9.9477 - acc: 0.0752     \n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 12s - loss: 9.9545 - acc: 0.0755    \n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 13s - loss: 10.0878 - acc: 0.0774    \n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 12s - loss: 10.0822 - acc: 0.0461    \n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 12s - loss: 10.0683 - acc: 0.0641    \n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 13s - loss: 9.3241 - acc: 0.0770    \n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 13s - loss: 10.1691 - acc: 0.0803    \n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 12s - loss: 10.0143 - acc: 0.0792   \n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 13s - loss: 9.4234 - acc: 0.0881    \n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 16s - loss: 9.9590 - acc: 0.0995    \n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 14s - loss: 9.7171 - acc: 0.1046    \n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 13s - loss: 9.5871 - acc: 0.1135    \n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 13s - loss: 9.9445 - acc: 0.1046    \n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 13s - loss: 9.1856 - acc: 0.0993    \n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 12s - loss: 9.9537 - acc: 0.1013     \n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 13s - loss: 9.9192 - acc: 0.1245    \n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 13s - loss: 9.8971 - acc: 0.0881    \n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 12s - loss: 9.4089 - acc: 0.1249    \n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 13s - loss: 9.8749 - acc: 0.1356    \n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 12s - loss: 9.6502 - acc: 0.1069    \n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 12s - loss: 9.1756 - acc: 0.1268    \n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 13s - loss: 9.7985 - acc: 0.0973    \n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 13s - loss: 10.2899 - acc: 0.1028    \n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 14s - loss: 9.8487 - acc: 0.1223    \n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 12s - loss: 9.8915 - acc: 0.1194    \n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 13s - loss: 9.4022 - acc: 0.0987    \n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 15s - loss: 9.8910 - acc: 0.1080    \n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 13s - loss: 9.0210 - acc: 0.1356    \n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 15s - loss: 9.1194 - acc: 0.1599    \n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 13s - loss: 9.8916 - acc: 0.1198    \n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 12s - loss: 9.4289 - acc: 0.1249    \n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 13s - loss: 9.5379 - acc: 0.1287    \n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 12s - loss: 9.7732 - acc: 0.1584    \n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 12s - loss: 9.5604 - acc: 0.1470    \n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 13s - loss: 9.5437 - acc: 0.1382    \n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 13s - loss: 9.7416 - acc: 0.1231    \n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 15s - loss: 9.0708 - acc: 0.1669    \n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 13s - loss: 9.3718 - acc: 0.1754    \n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 13s - loss: 9.7372 - acc: 0.1466    \n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 13s - loss: 9.2042 - acc: 0.1481    \n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 13s - loss: 8.8103 - acc: 0.1710    \n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 13s - loss: 9.1366 - acc: 0.1544    \n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 13s - loss: 9.8420 - acc: 0.1536    \n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 14s - loss: 9.3988 - acc: 0.1684    \n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 13s - loss: 9.3410 - acc: 0.1525    \n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 13s - loss: 9.2127 - acc: 0.1702    \n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 13s - loss: 9.7186 - acc: 0.1747    \n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 14s - loss: 9.3655 - acc: 0.1448    \n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 13s - loss: 9.7380 - acc: 0.1621    \n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 13s - loss: 8.9965 - acc: 0.1765    \n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 12s - loss: 9.6626 - acc: 0.1724    \n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 14s - loss: 9.7301 - acc: 0.1831    \n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 13s - loss: 9.4592 - acc: 0.1964    \n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 13s - loss: 9.5719 - acc: 0.1680    \n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 14s - loss: 9.6186 - acc: 0.1684    \n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 13s - loss: 9.6897 - acc: 0.1713    \n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 13s - loss: 9.9260 - acc: 0.1780    \n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 13s - loss: 9.1861 - acc: 0.1857    \n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 13s - loss: 9.2992 - acc: 0.1713    \n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 12s - loss: 9.3997 - acc: 0.1728    \n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 12s - loss: 9.3600 - acc: 0.2089    \n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 12s - loss: 9.1487 - acc: 0.1890    \n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 12s - loss: 9.1926 - acc: 0.1993    \n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 12s - loss: 9.6439 - acc: 0.1654    \n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 12s - loss: 9.6038 - acc: 0.1732    \n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 12s - loss: 9.6858 - acc: 0.1916    \n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 12s - loss: 9.2908 - acc: 0.2233    \n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 12s - loss: 9.3606 - acc: 0.2169    \n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 12s - loss: 9.1659 - acc: 0.1769    \n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 12s - loss: 9.5262 - acc: 0.2163    \n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 12s - loss: 9.4274 - acc: 0.1916    \n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 11s - loss: 9.1836 - acc: 0.1820    \n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 12s - loss: 9.2697 - acc: 0.2115    \n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 15s - loss: 9.2123 - acc: 0.2296    \n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 12s - loss: 9.1885 - acc: 0.1945    \n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 14s - loss: 9.5260 - acc: 0.2034    \n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 13s - loss: 9.3342 - acc: 0.2251    \n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 13s - loss: 10.0530 - acc: 0.2060    \n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 12s - loss: 9.9347 - acc: 0.2012     \n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 12s - loss: 8.9780 - acc: 0.2314    \n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 13s - loss: 9.3324 - acc: 0.2336    \n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 12s - loss: 9.0481 - acc: 0.2354    \n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 12s - loss: 9.3153 - acc: 0.2163    \n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 12s - loss: 9.1744 - acc: 0.2108    \n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 12s - loss: 8.7632 - acc: 0.2531    \n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 13s - loss: 9.4324 - acc: 0.1949    \n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 14s - loss: 9.2071 - acc: 0.2443    \n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 12s - loss: 8.9598 - acc: 0.2402    \n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 13s - loss: 9.3472 - acc: 0.2329    \n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 13s - loss: 9.3844 - acc: 0.1894    \n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 14s - loss: 9.5421 - acc: 0.2616    \n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 13s - loss: 9.3400 - acc: 0.2156    \n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 12s - loss: 9.1261 - acc: 0.2391    \n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 12s - loss: 9.1625 - acc: 0.2612    \n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 12s - loss: 9.1408 - acc: 0.2406    \n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 12s - loss: 9.6809 - acc: 0.2181    \n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 12s - loss: 9.4282 - acc: 0.2060    \n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 12s - loss: 9.4516 - acc: 0.2222    \n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 12s - loss: 9.1094 - acc: 0.2491    \n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 12s - loss: 9.1462 - acc: 0.2377    \n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 12s - loss: 9.0381 - acc: 0.2612    \n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 12s - loss: 9.0074 - acc: 0.2524    \n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 13s - loss: 9.2525 - acc: 0.2399    \n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 12s - loss: 8.7378 - acc: 0.2684    \n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 12s - loss: 9.9688 - acc: 0.2303    \n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 12s - loss: 9.1395 - acc: 0.2399    \n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 12s - loss: 9.2286 - acc: 0.2450    \n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 12s - loss: 9.5416 - acc: 0.2310    \n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 12s - loss: 9.6203 - acc: 0.2023    \n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 12s - loss: 9.4542 - acc: 0.2366    \n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 12s - loss: 9.9025 - acc: 0.2369    \n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 12s - loss: 9.0637 - acc: 0.2627    \n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 12s - loss: 8.9494 - acc: 0.2845    \n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 12s - loss: 9.2208 - acc: 0.2402    \n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 12s - loss: 9.4046 - acc: 0.2458    \n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 12s - loss: 9.0574 - acc: 0.2362    \n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 12s - loss: 9.6331 - acc: 0.2517    \n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 12s - loss: 9.0777 - acc: 0.2609    \n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 12s - loss: 9.4530 - acc: 0.2439    \n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 12s - loss: 9.0295 - acc: 0.2697    \n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 12s - loss: 9.4847 - acc: 0.2366    \n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 12s - loss: 9.4518 - acc: 0.2408    \n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 12s - loss: 9.5183 - acc: 0.2336    \n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 12s - loss: 8.8443 - acc: 0.3007    \n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 12s - loss: 9.6801 - acc: 0.2424    \n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 12s - loss: 8.6473 - acc: 0.2852    \n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 12s - loss: 8.5470 - acc: 0.2789    \n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 12s - loss: 9.5759 - acc: 0.2351    \n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 12s - loss: 9.0258 - acc: 0.2937    \n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 12s - loss: 8.8464 - acc: 0.3003    \n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 12s - loss: 8.5781 - acc: 0.2970    \n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 12s - loss: 9.4450 - acc: 0.2716    \n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 12s - loss: 9.0853 - acc: 0.2852    \n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 12s - loss: 9.4144 - acc: 0.2454    \n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 12s - loss: 9.6966 - acc: 0.2314    \n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 12s - loss: 9.3890 - acc: 0.2712    \n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 12s - loss: 9.2913 - acc: 0.2635    \n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 12s - loss: 9.0811 - acc: 0.2848    \n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 12s - loss: 9.0599 - acc: 0.2531    \n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 12s - loss: 9.7350 - acc: 0.2445    \n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 12s - loss: 9.4006 - acc: 0.2557    \n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 12s - loss: 9.1350 - acc: 0.2786    \n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 12s - loss: 9.1813 - acc: 0.2984    \n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 12s - loss: 9.3223 - acc: 0.2476    \n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 12s - loss: 9.5903 - acc: 0.2255    \n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 12s - loss: 9.5906 - acc: 0.2406    \n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 12s - loss: 8.8823 - acc: 0.3040    \n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 12s - loss: 8.3552 - acc: 0.3305    \n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 12s - loss: 9.3604 - acc: 0.2627    \n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 12s - loss: 9.5647 - acc: 0.2332    \n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 12s - loss: 9.0129 - acc: 0.3029    \n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 12s - loss: 9.2826 - acc: 0.2808    \n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 12s - loss: 9.9115 - acc: 0.2572     \n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 12s - loss: 9.3415 - acc: 0.2752    \n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 12s - loss: 9.3727 - acc: 0.2933    \n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 12s - loss: 9.7192 - acc: 0.2542    \n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 12s - loss: 8.5623 - acc: 0.3113    \n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 12s - loss: 9.4360 - acc: 0.2610    \n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 12s - loss: 9.7885 - acc: 0.2465    \n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 12s - loss: 9.4939 - acc: 0.2572    \n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 12s - loss: 8.8717 - acc: 0.2856    \n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 12s - loss: 9.5854 - acc: 0.2642    \n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 12s - loss: 9.3590 - acc: 0.3029    \n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 12s - loss: 8.9452 - acc: 0.2848    \n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 12s - loss: 8.9728 - acc: 0.3007    \n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 12s - loss: 9.2173 - acc: 0.2808    \n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 12s - loss: 8.8758 - acc: 0.2981    \n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 12s - loss: 8.8586 - acc: 0.2830    \n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 12s - loss: 9.5164 - acc: 0.2631    \n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 12s - loss: 8.9370 - acc: 0.2775    \n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 12s - loss: 8.8457 - acc: 0.2918    \n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 12s - loss: 9.1888 - acc: 0.2800    \n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 12s - loss: 9.2950 - acc: 0.2686    \n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 12s - loss: 8.9878 - acc: 0.2763    \n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 13s - loss: 8.9288 - acc: 0.3029    \n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 13s - loss: 9.1451 - acc: 0.2923    \n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 13s - loss: 9.6586 - acc: 0.2524    \n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 12s - loss: 10.4070 - acc: 0.2354    \n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 12s - loss: 9.4413 - acc: 0.2789    \n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 12s - loss: 9.2407 - acc: 0.2642    \n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 12s - loss: 9.1855 - acc: 0.3036    \n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 14s - loss: 9.3318 - acc: 0.2756    \n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 12s - loss: 9.5427 - acc: 0.2701    \n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 12s - loss: 8.8987 - acc: 0.3007    \n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 11s - loss: 9.6459 - acc: 0.2207    \n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 11s - loss: 8.9433 - acc: 0.2973    \n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 11s - loss: 9.3394 - acc: 0.2940    \n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 11s - loss: 9.4265 - acc: 0.2782    \n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 11s - loss: 9.3765 - acc: 0.2885    \n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 12s - loss: 9.1962 - acc: 0.2848    \n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 12s - loss: 9.5320 - acc: 0.2944    \n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 12s - loss: 9.1072 - acc: 0.2922    \n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 11s - loss: 9.1090 - acc: 0.2859    \n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 12s - loss: 9.3954 - acc: 0.2812    \n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 11s - loss: 8.8190 - acc: 0.3058    \n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 11s - loss: 8.6733 - acc: 0.3382    \n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 11s - loss: 9.3352 - acc: 0.2870    \n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 11s - loss: 9.4916 - acc: 0.2723    \n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 11s - loss: 8.7811 - acc: 0.3150    \n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 11s - loss: 9.0243 - acc: 0.2929    \n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 12s - loss: 9.4049 - acc: 0.2977    \n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 13s - loss: 8.9079 - acc: 0.3335    \n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 13s - loss: 9.2041 - acc: 0.2885    \n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 13s - loss: 8.9746 - acc: 0.2970    \n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 12s - loss: 9.0819 - acc: 0.2675    \n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 12s - loss: 9.1466 - acc: 0.2775    \n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 12s - loss: 8.9513 - acc: 0.3069    \n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 12s - loss: 9.6851 - acc: 0.2767    \n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 12s - loss: 8.8014 - acc: 0.3147    \n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 12s - loss: 9.1378 - acc: 0.3058    \n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 12s - loss: 8.9814 - acc: 0.3043    \n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 12s - loss: 8.2672 - acc: 0.3713    \n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 12s - loss: 9.0572 - acc: 0.3276    \n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 12s - loss: 9.1412 - acc: 0.2819    \n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 12s - loss: 9.1991 - acc: 0.2937    \n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 12s - loss: 9.3626 - acc: 0.2922    \n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 12s - loss: 9.2285 - acc: 0.3102    \n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 12s - loss: 8.9037 - acc: 0.2937    \n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 12s - loss: 9.4018 - acc: 0.2771    \n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 12s - loss: 8.7622 - acc: 0.3051    \n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 12s - loss: 9.1677 - acc: 0.2889    \n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 12s - loss: 8.7591 - acc: 0.3231    \n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 12s - loss: 8.9223 - acc: 0.3047    \n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 12s - loss: 8.7254 - acc: 0.3047    \n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 12s - loss: 9.2388 - acc: 0.3029    \n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 12s - loss: 8.7787 - acc: 0.3158    \n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 12s - loss: 9.4837 - acc: 0.3036    \n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 12s - loss: 9.5623 - acc: 0.2775    \n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 11s - loss: 9.1231 - acc: 0.2863    \n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 12s - loss: 9.3610 - acc: 0.2849    \n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 12s - loss: 9.1080 - acc: 0.2649    \n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 13s - loss: 8.8896 - acc: 0.3099    \n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 12s - loss: 9.2593 - acc: 0.3136    \n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 13s - loss: 9.3724 - acc: 0.2767    \n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 12s - loss: 9.0474 - acc: 0.2940    \n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 12s - loss: 9.7052 - acc: 0.2804    \n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 12s - loss: 9.1302 - acc: 0.2896    \n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 12s - loss: 8.6404 - acc: 0.3113    \n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 12s - loss: 9.1540 - acc: 0.2859    \n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 12s - loss: 9.0986 - acc: 0.3099    \n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 12s - loss: 9.0734 - acc: 0.2996    \n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 12s - loss: 8.8620 - acc: 0.3180    \n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 12s - loss: 9.4449 - acc: 0.2631    \n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 12s - loss: 8.7330 - acc: 0.3305    \n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 12s - loss: 9.0866 - acc: 0.3213    \n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 12s - loss: 8.8739 - acc: 0.3301    \n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 12s - loss: 8.9884 - acc: 0.2955    \n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 12s - loss: 9.4561 - acc: 0.3033    \n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 12s - loss: 8.8872 - acc: 0.2973    \n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 12s - loss: 9.0222 - acc: 0.3032    \n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 11s - loss: 9.2568 - acc: 0.3172    \n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 12s - loss: 9.1336 - acc: 0.3213    \n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 12s - loss: 9.1707 - acc: 0.3224    \n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 12s - loss: 9.0551 - acc: 0.3290    \n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 12s - loss: 9.4263 - acc: 0.2959    \n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 12s - loss: 9.3104 - acc: 0.2841    \n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 12s - loss: 8.9984 - acc: 0.3147    \n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 11s - loss: 9.0384 - acc: 0.3125    \n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 12s - loss: 8.5601 - acc: 0.3438    \n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 12s - loss: 9.2876 - acc: 0.2859    \n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 12s - loss: 9.5801 - acc: 0.2738    \n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 11s - loss: 8.8599 - acc: 0.3357    \n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 12s - loss: 8.6540 - acc: 0.3327    \n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 11s - loss: 9.5273 - acc: 0.3095    \n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 12s - loss: 9.2156 - acc: 0.3265    \n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 12s - loss: 8.7661 - acc: 0.3235    \n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 12s - loss: 8.6390 - acc: 0.3195    \n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 12s - loss: 9.1587 - acc: 0.3209    \n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 12s - loss: 9.1520 - acc: 0.3305    \n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 12s - loss: 9.1465 - acc: 0.3313    \n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 12s - loss: 9.4457 - acc: 0.2940    \n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 12s - loss: 8.7256 - acc: 0.3504    \n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 12s - loss: 9.1920 - acc: 0.3058    \n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 12s - loss: 9.2842 - acc: 0.2870    \n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 12s - loss: 8.8691 - acc: 0.3161    \n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 12s - loss: 9.2919 - acc: 0.3452    \n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 11s - loss: 8.8103 - acc: 0.3320    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f184a10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x, y, batch_size=32),\n",
    "                    steps_per_epoch=len(x) / 32, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander_cls_train.csv : 1.57316931556, 0.726102941176\n",
      "Alexander_cls_test.csv : 4.03173589706, 0.321557971014\n",
      "Alexander_cls_test1.csv : 2.00173806443, 0.5625\n",
      "Alexander_cls_test2.csv : 7.46967282015, 0.0496323529412\n",
      "Alexander_cls_test3.csv : 2.92800291847, 0.330882352941\n",
      "Alexander_cls_test4.csv : 3.76812979754, 0.332720588235\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True\n",
    ")\n",
    "\n",
    "test_paths = ['Alexander_cls_train.csv',\n",
    "             'Alexander_cls_test.csv',\n",
    "             'Alexander_cls_test1.csv',\n",
    "             'Alexander_cls_test2.csv',\n",
    "             'Alexander_cls_test3.csv',\n",
    "             'Alexander_cls_test4.csv']\n",
    "\n",
    "for test_path in test_paths:\n",
    "    x_test, y_test, num_classes = process_file(test_path)\n",
    "    test_datagen.fit(x_test)\n",
    "    score = model.evaluate_generator(test_datagen.flow(x_test, y_test, batch_size=32), steps=len(x_test) / 32)\n",
    "    print test_path + ' : ' + ', '.join(str(x) for x in score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(x, y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(np.argmax(y_predict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 198, 198, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 66, 66, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 19, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 111)               511599    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 111)               0         \n",
      "=================================================================\n",
      "Total params: 604,271\n",
      "Trainable params: 604,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# спросить про 500 samples на класс (хорошо, но можно оверфитнуться)\n",
    "# когда 50 сэмплов хорошо, обычно плохо"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
